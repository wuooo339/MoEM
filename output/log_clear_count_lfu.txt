CUDA extension not installed.
CUDA extension not installed.
Using /home/user/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /home/user/.cache/torch_extensions/py310_cu124/prefetch/build.ninja...
Building extension module prefetch...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Do not detect pre-installed ops, use JIT mode
[WARNING] FlashAttention is not available in the current environment. Using default attention.
[1/2] c++ -MMD -MF expert_dispatcher.o.d -DTORCH_EXTENSION_NAME=prefetch -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/home/user/offload/MoE-Infinity/moe_infinity/ops/core -isystem /home/user/miniconda3/envs/moe-infinity/lib/python3.10/site-packages/torch/include -isystem /home/user/miniconda3/envs/moe-infinity/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/user/miniconda3/envs/moe-infinity/lib/python3.10/site-packages/torch/include/TH -isystem /home/user/miniconda3/envs/moe-infinity/lib/python3.10/site-packages/torch/include/THC -isystem /home/user/miniconda3/envs/moe-infinity/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -g -Wall -O3 -std=c++17 -shared -fPIC -Wno-reorder -march=native -fopenmp -D__AVX256__ -I/usr/local/cuda/include -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lpthread -c /home/user/offload/MoE-Infinity/moe_infinity/ops/core/parallel/expert_dispatcher.cpp -o expert_dispatcher.o 
/home/user/offload/MoE-Infinity/moe_infinity/ops/core/parallel/expert_dispatcher.cpp: In member function â€˜void ExpertDispatcher::GPUFetchFunc(int)â€™:
/home/user/offload/MoE-Infinity/moe_infinity/ops/core/parallel/expert_dispatcher.cpp:373:25: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜long unsigned intâ€™ [-Wsign-compare]
  373 |       for (int i = 0; i < num_experts; ++i) {
      |                       ~~^~~~~~~~~~~~~
/home/user/offload/MoE-Infinity/moe_infinity/ops/core/parallel/expert_dispatcher.cpp:374:27: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜long unsigned intâ€™ [-Wsign-compare]
  374 |         for (int j = 0; j < num_layers; ++j) {
      |                         ~~^~~~~~~~~~~~
/home/user/offload/MoE-Infinity/moe_infinity/ops/core/parallel/expert_dispatcher.cpp:383:41: warning: comparison of integer expressions of different signedness: â€˜uint64_tâ€™ {aka â€˜long unsigned intâ€™} and â€˜intâ€™ [-Wsign-compare]
  383 |               node->incache_visit_count < min_visit_count &&
      |               ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~
/home/user/offload/MoE-Infinity/moe_infinity/ops/core/parallel/expert_dispatcher.cpp: In member function â€˜void ExpertDispatcher::GPUExecFunc(int)â€™:
/home/user/offload/MoE-Infinity/moe_infinity/ops/core/parallel/expert_dispatcher.cpp:472:12: warning: variable â€˜startâ€™ set but not used [-Wunused-but-set-variable]
  472 |       auto start = TIME_NOW;
      |            ^~~~~
/home/user/offload/MoE-Infinity/moe_infinity/ops/core/parallel/expert_dispatcher.cpp:524:12: warning: variable â€˜endâ€™ set but not used [-Wunused-but-set-variable]
  524 |       auto end = TIME_NOW;
      |            ^~~
/home/user/offload/MoE-Infinity/moe_infinity/ops/core/parallel/expert_dispatcher.cpp: In member function â€˜std::vector<std::tuple<at::Tensor, int, int, int> > ExpertDispatcher::Wait()â€™:
/home/user/offload/MoE-Infinity/moe_infinity/ops/core/parallel/expert_dispatcher.cpp:575:7: warning: unused variable â€˜wait_countâ€™ [-Wunused-variable]
  575 |   int wait_count = 0;
      |       ^~~~~~~~~~
[2/2] c++ logger.o cuda_utils.o model_topology.o archer_prefetch_handle.o task_scheduler.o task_thread.o memory_pool.o stream_pool.o host_caching_allocator.o device_caching_allocator.o py_archer_prefetch.o expert_dispatcher.o expert_module.o archer_aio_thread.o archer_prio_aio_handle.o archer_aio_utils.o archer_aio_threadpool.o archer_tensor_handle.o archer_tensor_index.o thread.o exception.o date.o process_info.o logging.o log_file.o timestamp.o file_util.o countdown_latch.o timezone.o log_stream.o thread_pool.o -shared -L/home/user/miniconda3/envs/moe-infinity/lib/python3.10/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o prefetch.so
Loading extension module prefetch...
Time to load prefetch op: 40.42977285385132 seconds
Loading model from offload_path ...
DeepseekV2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
[20250415 10:54:07.001183Z ][396942 ][INFO  ]Create ArcherAioThread for thread:  0 - archer_aio_thread.cpp:12
[20250415 10:54:07.001755Z ][396942 ][INFO  ]Loading index file from  /home/user/offload/deepseek-v2-param/deepseek-v2-lite/archer_index - archer_tensor_handle.cpp:44
[20250415 10:54:07.009224Z ][396942 ][INFO  ]Index file size  5291 - archer_tensor_handle.cpp:50
[20250415 10:54:07.011148Z ][396942 ][INFO  ]Device count  1 - archer_prefetch_handle.cpp:39
[20250415 10:54:07.011153Z ][396942 ][INFO  ]Enabled peer access for all devices - archer_prefetch_handle.cpp:62
[20250415 10:54:09.347601Z ][396942 ][INFO  ]Moving dense parameters to GPU - model_topology.cpp:521

The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.
`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48
DeepseekV2Config {
  "_name_or_path": "/share-data/wzk-1/model/deepseek-v2-lite",
  "architectures": [
    "DeepseekV2ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "auto_map": {
    "AutoConfig": "configuration_deepseek.DeepseekV2Config",
    "AutoModel": "modeling_deepseek.DeepseekV2Model",
    "AutoModelForCausalLM": "modeling_deepseek.DeepseekV2ForCausalLM"
  },
  "aux_loss_alpha": 0.001,
  "bos_token_id": 100000,
  "eos_token_id": 100001,
  "ep_size": 1,
  "first_k_dense_replace": 1,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 10944,
  "kv_lora_rank": 512,
  "max_position_embeddings": 163840,
  "model_type": "deepseek_v2",
  "moe_intermediate_size": 1408,
  "moe_layer_freq": 1,
  "n_group": 1,
  "n_routed_experts": 64,
  "n_shared_experts": 2,
  "norm_topk_prob": false,
  "num_attention_heads": 16,
  "num_experts_per_tok": 6,
  "num_hidden_layers": 27,
  "num_key_value_heads": 16,
  "pretraining_tp": 1,
  "q_lora_rank": null,
  "qk_nope_head_dim": 128,
  "qk_rope_head_dim": 64,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "beta_fast": 32,
    "beta_slow": 1,
    "factor": 40,
    "mscale": 0.707,
    "mscale_all_dim": 0.707,
    "original_max_position_embeddings": 4096,
    "type": "yarn"
  },
  "rope_theta": 10000,
  "routed_scaling_factor": 1.0,
  "scoring_func": "softmax",
  "seq_aux": true,
  "tie_word_embeddings": false,
  "topk_group": 1,
  "topk_method": "greedy",
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.3",
  "use_cache": true,
  "v_head_dim": 128,
  "vocab_size": 102400
}

input:  è¯·é€æ­¥è§£å†³ä»¥ä¸‹é—®é¢˜ï¼Œå¹¶è§£é‡Šæ¯æ­¥æ¨ç†è¿‡ç¨‹ï¼š
1. è‹¥3å°æœºå™¨5å°æ—¶ç”Ÿäº§180ä¸ªé›¶ä»¶ï¼Œ7å°æœºå™¨8å°æ—¶å¯ç”Ÿäº§å¤šå°‘é›¶ä»¶ï¼Ÿ
2. ç”²æ¯”ä¹™å¤§6å²ï¼Œ5å¹´å‰ç”²å¹´é¾„æ˜¯ä¹™çš„2å€ï¼Œæ±‚ä¸¤äººç°åœ¨å¹´é¾„ã€‚
3. è®¡ç®—ï¼š(2Â³ Ã— âˆš16) Ã· (4â»Â¹ + logâ‚‚8)
4. ä¸€ä¸ªéª°å­è¿ç»­æ·3æ¬¡ï¼Œè‡³å°‘å‡ºç°ä¸€æ¬¡6çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
5. ç”¨è´å¶æ–¯å®šç†è§£é‡Šï¼šæ–°å† æ£€æµ‹å‡†ç¡®ç‡98%ï¼Œäººç¾¤æ„ŸæŸ“ç‡1%ï¼ŒæŸäººæ£€æµ‹é˜³æ€§æ—¶å®é™…æ‚£ç—…çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
è¦æ±‚ï¼šåˆ†æ­¥éª¤å±•ç¤ºè®¡ç®—è¿‡ç¨‹ï¼Œæœ€ç»ˆç­”æ¡ˆç”¨ã€ã€‘æ ‡æ³¨ã€‚
inputs ...
torch.Size([1, 168])
outputs_text ...
write out information.


1. è‹¥3å°æœºå™¨5å°æ—¶ç”Ÿäº§180ä¸ªé›¶ä»¶ï¼Œ7å°æœºå™¨8å°æ—¶å¯ç”Ÿäº§å¤šå°‘é›¶ä»¶ï¼Ÿ

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æ‰¾å‡ºæ¯å°æœºå™¨æ¯å°æ—¶çš„ç”Ÿäº§é‡ã€‚ç”±é¢˜ç›®å¯çŸ¥ï¼Œ3å°æœºå™¨5å°æ—¶å¯ä»¥ç”Ÿäº§180ä¸ªé›¶ä»¶ï¼Œæ‰€ä»¥æ¯å°æœºå™¨æ¯å°æ—¶çš„ç”Ÿäº§é‡æ˜¯ï¼š

180ä¸ªé›¶ä»¶ / (3å°æœºå™¨ * 5å°æ—¶) = 12ä¸ªé›¶ä»¶/å°æ—¶/å°

ç„¶å
-----------------------------------------------
Prefilling time: 3.753654956817627 seconds
Decoding time: None seconds
Decoding iterations: 100
Decoding time per iteration: 0.27884647369384763 seconds
ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ªç”Ÿäº§ç‡æ¥è®¡ç®—7å°æœºå™¨8å°æ—¶å¯ä»¥ç”Ÿäº§å¤šå°‘é›¶ä»¶ï¼š

7å°æœºå™¨ * 8å°æ—¶ * 12ä¸ªé›¶ä»¶/å°æ—¶/å° = 672ä¸ªé›¶ä»¶

æ‰€ä»¥ï¼Œ7å°æœºå™¨8å°æ—¶å¯ä»¥ç”Ÿäº§672ä¸ªé›¶ä»¶ã€‚

ã€672ã€‘

2. ç”²æ¯”ä¹™å¤§6å²ï¼Œ5å¹´å‰ç”²å¹´é¾„æ˜¯ä¹™çš„2å€ï¼Œæ±‚ä¸¤äººç°åœ¨å¹´é¾„ã€‚

è®¾ç”²ç°åœ¨çš„
-----------------------------------------------
Prefilling time: 3.753654956817627 seconds
Decoding time: None seconds
Decoding iterations: 200
Decoding time per iteration: 0.2801589226722717 seconds
å¹´é¾„ä¸ºxå²ï¼Œä¹™ç°åœ¨çš„å¹´é¾„ä¸ºyå²ã€‚æ ¹æ®é¢˜ç›®ï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹ä¸¤ä¸ªæ–¹ç¨‹ï¼š

x = y + 6 ï¼ˆç”²æ¯”ä¹™å¤§6å²ï¼‰
x - 5 = 2 * (y - 5) ï¼ˆ5å¹´å‰ç”²å¹´é¾„æ˜¯ä¹™çš„2å€ï¼‰

æˆ‘ä»¬å¯ä»¥å…ˆè§£ç¬¬äºŒä¸ªæ–¹ç¨‹ï¼Œå¾—åˆ°x = 2y - 5ã€‚ç„¶åå°†è¿™ä¸ªç»“æœä»£å…¥ç¬¬ä¸€ä¸ªæ–¹ç¨‹ï¼Œå¾—åˆ°ï¼š

2y 
-----------------------------------------------
Prefilling time: 3.753654956817627 seconds
Decoding time: None seconds
Decoding iterations: 300
Decoding time per iteration: 0.2887167970339457 seconds
- 5 = y + 6
y = 11

å°†y = 11ä»£å…¥ç¬¬ä¸€ä¸ªæ–¹ç¨‹ï¼Œå¾—åˆ°ï¼š

x = 11 + 6 = 17

æ‰€ä»¥ï¼Œç”²ç°åœ¨17å²ï¼Œä¹™ç°åœ¨11å²ã€‚

ã€ç”²17å²ï¼Œä¹™11å²ã€‘

3. è®¡ç®—ï¼š(2Â³ Ã— âˆš16) Ã· (4â»Â¹ + logâ‚‚8)

-----------------------------------------------
Prefilling time: 3.753654956817627 seconds
Decoding time: None seconds
Decoding iterations: 400
Decoding time per iteration: 0.290025018453598 seconds

é¦–å…ˆï¼Œè®¡ç®—2Â³ Ã— âˆš16ï¼š

2Â³ = 8
8 Ã— âˆš16 = 8 * 4 = 32

ç„¶åï¼Œè®¡ç®—4â»Â¹ + logâ‚‚8ï¼š

4â»Â¹ = 1/4
logâ‚‚8 = 3ï¼ˆå› ä¸º2Â³ = 8ï¼‰

æ‰€ä»¥ï¼Œ4â»Â¹ + logâ‚‚8 = 1/4 + 3 = 
-----------------------------------------------
Prefilling time: 3.753654956817627 seconds
Decoding time: None seconds
Decoding iterations: 500
Decoding time per iteration: 0.28801148653030395 seconds
13/4

Prefilling time: 3.753654956817627 seconds
Decoding time: 144.00650477409363 seconds
Decoding iterations: 500
Decoding time per iteration: 0.28801300954818726 seconds
Input tokens: 168
input:  è¯·ç”¨Pythonå®ç°ä»¥ä¸‹éœ€æ±‚ï¼š
1. ç¼–å†™ä¸€ä¸ªæ”¯æŒLRUç¼“å­˜æœºåˆ¶çš„è£…é¥°å™¨ç±»ï¼ŒåŒ…å«get/putæ–¹æ³•
2. ç”¨PyTorchæ„å»ºä¸€ä¸ª3å±‚MoEæ¨¡å‹ï¼š
   - ä¸“å®¶æ•°=4ï¼Œé—¨æ§ç½‘ç»œä¸ºç®€å•çº¿æ€§å±‚
   - æ¯ä¸“å®¶ä¸ºå«Dropoutçš„å…¨è¿æ¥ç½‘ç»œ
   - æ”¯æŒåŠ¨æ€ä¸“å®¶æ¿€æ´»æ•°ï¼ˆtop_k=2ï¼‰
3. ä¿®å¤ä»¥ä¸‹ä»£ç çš„BUGï¼ˆæç¤ºï¼šæ¶‰åŠå¼‚æ­¥åç¨‹ï¼‰ï¼š
   async def fetch_data():
       results = []
       for url in urls:
           data = await session.get(url)  # æŠ¥é”™ä½ç½®
           results.append(data.json())
       return results
è¦æ±‚ï¼šä»£ç éœ€å¯ç›´æ¥è¿è¡Œï¼Œå…³é”®å¤„æ·»åŠ æ³¨é‡Šã€‚
inputs ...
torch.Size([1, 178])
outputs_text ...
write out information.


```python
import asyncio
import aiohttp

# 1. ç¼–å†™ä¸€ä¸ªæ”¯æŒLRUç¼“å­˜æœºåˆ¶çš„è£…é¥°å™¨ç±»ï¼ŒåŒ…å«get/putæ–¹æ³•
class LRUCache:
    def __init__(self, maxsize=10):
        self.cache = {}
        self.maxsize = maxsize

    def get(self, key):
        if key in self.cache:
            value = 
-----------------------------------------------
Prefilling time: 2.21323823928833 seconds
Decoding time: None seconds
Decoding iterations: 100
Decoding time per iteration: 0.29341973304748536 seconds
self.cache[key]
            self.cache.pop(key)
            self.cache[key] = value
            return value
        else:
            return None

    def put(self, key, value):
        if len(self.cache) >= self.maxsize:
            self.cache.pop(next(iter(self.cache)))
        self.cache[key] = value

# 2. ç”¨
-----------------------------------------------
Prefilling time: 2.21323823928833 seconds
Decoding time: None seconds
Decoding iterations: 200
Decoding time per iteration: 0.31376935958862306 seconds
PyTorchæ„å»ºä¸€ä¸ª3å±‚MoEæ¨¡å‹
import torch
import torch.nn as nn
import torch.nn.functional as F

class MoE(nn.Module):
    def __init__(self, num_experts=4, top_k=2):
        super(MoE, self).__init__()
        self.num_experts = num_experts
        self.top_k = top_k
        self.experts = 
-----------------------------------------------
Prefilling time: 2.21323823928833 seconds
Decoding time: None seconds
Decoding iterations: 300
Decoding time per iteration: 0.31109001477559406 seconds
nn.ModuleList([nn.Linear(10, 10) for _ in range(num_experts)])
        self.gate_linear = nn.Linear(10, num_experts)

    def forward(self, x):
        gate = F.softmax(self.gate_linear(x), dim=1)
        return sum((expert(x) * gate[i]) for i, expert in enumerate(self.experts))


-----------------------------------------------
Prefilling time: 2.21323823928833 seconds
Decoding time: None seconds
Decoding iterations: 400
Decoding time per iteration: 0.3151435595750809 seconds
# 3. ä¿®å¤ä»¥ä¸‹ä»£ç çš„BUGï¼ˆæç¤ºï¼šæ¶‰åŠå¼‚æ­¥åç¨‹ï¼‰
async def fetch_data():
    results = []
    for url in urls:
        async with aiohttp.ClientSession() as session:
            data = await session.get(url)  # æŠ¥é”™ä½ç½®
            results.append(await data.json())  # æŠ¥é”™ä½ç½®
    return results

# æµ‹è¯•ä»£ç 
if 
-----------------------------------------------
Prefilling time: 2.21323823928833 seconds
Decoding time: None seconds
Decoding iterations: 500
Decoding time per iteration: 0.309661949634552 seconds
__name__ ==
Prefilling time: 2.21323823928833 seconds
Decoding time: 154.8315532207489 seconds
Decoding iterations: 500
Decoding time per iteration: 0.3096631064414978 seconds
Input tokens: 178
input:  è¯·å®Œæˆä»¥ä¸‹è·¨è¯­è¨€ä»»åŠ¡ï¼š
1. å°†ä¸­æ–‡è°šè¯­'å¡ç¿å¤±é©¬ï¼Œç„‰çŸ¥éç¦'ç¿»è¯‘æˆè‹±æ–‡ã€æ³•æ–‡ã€æ—¥æ–‡ï¼Œå¹¶åˆ†åˆ«ç»™å‡ºæ–‡åŒ–èƒŒæ™¯è§£é‡Š
2. æŠŠè¥¿ç­ç‰™è¯­æ­Œè¯'Despacito'ï¼ˆåŸæ„ï¼šæ…¢æ…¢æ¥ï¼‰æœ¬åœ°åŒ–ä¸ºä¸­æ–‡å››å­—æˆè¯­é£æ ¼
3. åˆ†æå¾·è¯­å¤åˆè¯'Schadenfreude'ï¼ˆå¹¸ç¾ä¹ç¥¸ï¼‰åœ¨ä¸­æ–‡/é˜¿æ‹‰ä¼¯è¯­ä¸­çš„ç­‰æ•ˆè¡¨è¾¾
4. ä¸ºæ—¥æœ¬å®¢æˆ·æ’°å†™å•†åŠ¡é‚®ä»¶ï¼ˆæ—¥æ–‡ï¼‰ï¼Œä¸»é¢˜ï¼šAIåˆä½œé¡¹ç›®å»¶æœŸè¯·æ±‚ï¼ˆéœ€ç¬¦åˆæ•¬è¯­è§„èŒƒï¼‰
è¦æ±‚ï¼šè¯‘æ–‡éœ€ç¬¦åˆç›®æ ‡è¯­è¨€æ–‡åŒ–ä¹ æƒ¯ï¼Œé‡è¦æ¦‚å¿µé™„åŠ è¯´æ˜ã€‚
inputs ...
torch.Size([1, 148])
outputs_text ...
write out information.


1. ä¸­æ–‡è°šè¯­'å¡ç¿å¤±é©¬ï¼Œç„‰çŸ¥éç¦'ç¿»è¯‘æˆè‹±æ–‡ã€æ³•æ–‡ã€æ—¥æ–‡ï¼Œå¹¶åˆ†åˆ«ç»™å‡ºæ–‡åŒ–èƒŒæ™¯è§£é‡Šï¼š

- è‹±æ–‡ï¼š"When the cat's away, the mice will play."
- æ³•æ–‡ï¼š"Quand le chat n'est pas lÃ , les souris jouent."
- æ—¥æ–‡ï¼š"çŒ¿ãŒéŠ
-----------------------------------------------
Prefilling time: 2.054361581802368 seconds
Decoding time: None seconds
Decoding iterations: 100
Decoding time per iteration: 0.2896019744873047 seconds
ã¶ãªã‚‰ã€å²¸ã‚’è¦‹ã‚ã€‚"ï¼ˆãˆã‚“ãŒã‚ãã¶ãªã‚‰ã€ãã—ã‹ã‚ã¿ã‚ï¼‰

è‹±æ–‡è§£é‡Šï¼šThis English proverb suggests that when someone is not around to supervise or control a situation, others may take advantage of the opportunity to do as they please. It's a play on the Chinese proverb, suggesting that what may seem like a misfortune could actually turn out to be a blessing in disguise.

-----------------------------------------------
Prefilling time: 2.054361581802368 seconds
Decoding time: None seconds
Decoding iterations: 200
Decoding time per iteration: 0.30697748899459837 seconds

æ³•æ–‡è§£é‡Šï¼šCette expression franÃ§aise signifie que lorsque quelqu'un n'est pas prÃ©sent pour surveiller ou contrÃ´ler une situation, les autres peuvent profiter de l'opportunitÃ© pour faire ce qu'ils veulent. Elle joue sur le proverbe chinois, suggÃ©rant que ce qui peut sembler Ãªtre un malheur pourrait en rÃ©alitÃ© se 
-----------------------------------------------
Prefilling time: 2.054361581802368 seconds
Decoding time: None seconds
Decoding iterations: 300
Decoding time per iteration: 0.30254830757776896 seconds
rÃ©vÃ©ler Ãªtre une bÃ©nÃ©diction cachÃ©e.

æ—¥æ–‡è§£é‡Šï¼šã“ã®æ—¥æœ¬ã®è«ºã¯ã€çŒ¿ãŒéŠã‚“ã§ã„ã‚‹ã¨ã„ã†ã“ã¨ãŒé­šãŒé‡£ã‚Œã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¦ã„ã¾ã™ã€‚ã¤ã¾ã‚Šã€æ‚ªã„ã“ã¨ãŒã‚ã£ã¦ã‚‚ã€ãã‚ŒãŒä»–ã®è‰¯
-----------------------------------------------
Prefilling time: 2.054361581802368 seconds
Decoding time: None seconds
Decoding iterations: 400
Decoding time per iteration: 0.3036815541982651 seconds
ã„ã“ã¨ã«ã¤ãªãŒã‚‹ã“ã¨ãŒã‚ã‚‹ã¨ã„ã†æ„å‘³ã§ã™ã€‚

2. è¥¿ç­ç‰™è¯­æ­Œè¯'Despacito'æœ¬åœ°åŒ–ä¸ºä¸­æ–‡å››å­—æˆè¯­é£æ ¼ï¼š

- æœ¬åœ°åŒ–ï¼š"æ¸å…¥ä½³å¢ƒ"

3. å¾·è¯­å¤åˆè¯'Schadenfreude'ï¼ˆå¹¸ç¾ä¹ç¥¸ï¼‰åœ¨ä¸­æ–‡/é˜¿æ‹‰ä¼¯è¯­ä¸­çš„ç­‰æ•ˆè¡¨è¾¾ï¼š

- ä¸­æ–‡ï¼š"å¹¸ç¾ä¹ç¥¸"
- é˜¿æ‹‰ä¼¯
-----------------------------------------------
Prefilling time: 2.054361581802368 seconds
Decoding time: None seconds
Decoding iterations: 500
Decoding time per iteration: 0.3029146575927734 seconds
è¯­
Prefilling time: 2.054361581802368 seconds
Decoding time: 151.4578824043274 seconds
Decoding iterations: 500
Decoding time per iteration: 0.3029157648086548 seconds
Input tokens: 148
input:  è¯·ç”¨å­¦æœ¯è®ºæ–‡é£æ ¼å›ç­”ï¼š
1. å¯¹æ¯”Transformer/RNN/GNNåœ¨æ—¶åºé¢„æµ‹ä¸­çš„ä¼˜åŠ£ï¼ˆéœ€å¼•2020å¹´åè®ºæ–‡ï¼‰
2. ç”¨æ§åˆ¶è®ºè§£é‡ŠAlphaGoçš„å†³ç­–æ ‘ä¼˜åŒ–è¿‡ç¨‹
3. åˆ—å‡ºé‡å­è®¡ç®—å¯¹å¯†ç å­¦çš„ä¸‰å¤§å½±å“ï¼Œå¹¶è¯´æ˜Shorç®—æ³•åŸç†
4. æ’°å†™æ‘˜è¦ï¼šMoEæ¨¡å‹åœ¨è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²çš„æŒ‘æˆ˜ï¼ˆ200å­—å†…ï¼Œå«èƒ½è€—/ç²¾åº¦/å»¶è¿ŸæŒ‡æ ‡ï¼‰
è¦æ±‚ï¼šå…³é”®è®ºç‚¹éœ€æ ‡æ³¨å‚è€ƒæ–‡çŒ®ï¼ˆæ ¼å¼ï¼šAuthor et al., Yearï¼‰ï¼Œé¿å…ä¸»è§‚è¡¨è¿°ã€‚
inputs ...
torch.Size([1, 127])
outputs_text ...
write out information.


1. å¯¹æ¯”Transformer/RNN/GNNåœ¨æ—¶åºé¢„æµ‹ä¸­çš„ä¼˜åŠ£

Transformerã€RNNå’ŒGNNåœ¨æ—¶åºé¢„æµ‹ä»»åŠ¡ä¸­å„æœ‰ä¼˜åŠ£ã€‚Transformeræ¨¡å‹ç”±äºå…¶è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤Ÿæ•æ‰é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œé€‚åˆå¤„ç†åºåˆ—æ•°æ®ï¼Œä½†åœ¨å¤„ç†æ—¶åºæ•°æ®æ—¶å¯èƒ½éœ€è¦è¾ƒé•¿çš„è®­ç»ƒæ—¶é—´ã€‚RNNï¼ˆå¦‚LSTMå’ŒGRUï¼‰èƒ½å¤Ÿåˆ©ç”¨å¾ªç¯ç»“æ„å¤„ç†åºåˆ—æ•°æ®ï¼Œé€‚åˆå¤„ç†æ—¶é—´è·¨åº¦è¾ƒå¤§çš„æ—¶åºæ•°æ®ï¼Œä½†å…¶æ¢¯åº¦
-----------------------------------------------
Prefilling time: 2.134551525115967 seconds
Decoding time: None seconds
Decoding iterations: 100
Decoding time per iteration: 0.2816530013084412 seconds
æ¶ˆå¤±é—®é¢˜é™åˆ¶äº†å…¶å¤„ç†é•¿è·ç¦»ä¾èµ–çš„èƒ½åŠ›ã€‚GNNï¼ˆå›¾ç¥ç»ç½‘ç»œï¼‰èƒ½å¤Ÿåˆ©ç”¨å›¾ç»“æ„æ•°æ®ï¼Œé€‚åˆå¤„ç†å…·æœ‰å¤æ‚å…³ç³»çš„æ•°æ®ï¼Œä½†åœ¨æ—¶åºé¢„æµ‹ä»»åŠ¡ä¸­ï¼Œå…¶æ€§èƒ½å¯èƒ½å—é™äºå›¾çš„æ„å»ºå’Œæ›´æ–°ã€‚

å‚è€ƒæ–‡çŒ®ï¼š
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., & Gomez, A. N. (2017). Attention is 
-----------------------------------------------
Prefilling time: 2.134551525115967 seconds
Decoding time: None seconds
Decoding iterations: 200
Decoding time per iteration: 0.2859745442867279 seconds
all you need. Advances in neural information processing systems, 30.

2. ç”¨æ§åˆ¶è®ºè§£é‡ŠAlphaGoçš„å†³ç­–æ ‘ä¼˜åŒ–è¿‡ç¨‹

AlphaGoçš„å†³ç­–æ ‘ä¼˜åŒ–è¿‡ç¨‹å¯ä»¥ç”¨æ§åˆ¶è®ºæ¥è§£é‡Šã€‚åœ¨æ§åˆ¶è®ºä¸­ï¼Œç³»ç»Ÿè¢«è§†ä¸ºä¸€ä¸ªä¿¡æ¯å¤„ç†ç³»ç»Ÿï¼Œå…¶è¾“å…¥æ˜¯ç¯å¢ƒä¿¡æ¯ï¼Œè¾“å‡ºæ˜¯ç³»ç»Ÿå¯¹ç¯å¢ƒçš„å“åº”ã€‚AlphaGoçš„å†³ç­–æ ‘é€šè¿‡å­¦ä¹ å¤§é‡çš„æ£‹å±€æ•°æ®ï¼Œæ„å»ºäº†ä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿé¢„æµ‹æ¯ä¸€æ­¥æ£‹çš„æœ€ä½³è½å­ä½ç½®
-----------------------------------------------
Prefilling time: 2.134551525115967 seconds
Decoding time: None seconds
Decoding iterations: 300
Decoding time per iteration: 0.2831123979886373 seconds
ã€‚é€šè¿‡ä¸æ–­çš„è‡ªæˆ‘å¯¹å¼ˆå’Œåé¦ˆï¼ŒAlphaGoçš„å†³ç­–æ ‘ä¸æ–­ä¼˜åŒ–å…¶é¢„æµ‹æ¨¡å‹ï¼Œä»¥æ›´å¥½åœ°æ§åˆ¶æ£‹å±€çš„å‘å±•ï¼Œæœ€ç»ˆè¾¾åˆ°å¯¹å¼ˆçš„èƒœåˆ©ã€‚

å‚è€ƒæ–‡çŒ®ï¼š
Silver, D., Huang, A., Maddison, C. J., Schrittwieser, J., Antonoglou, I., Lai, M., ... & Sifre, L. (2017). Mastering the game of Go with deep neural networks and tree 
-----------------------------------------------
Prefilling time: 2.134551525115967 seconds
Decoding time: None seconds
Decoding iterations: 400
Decoding time per iteration: 0.2814258539676666 seconds
search. Nature, 550(7676), 354-359.

3. åˆ—å‡ºé‡å­è®¡ç®—å¯¹å¯†ç å­¦çš„ä¸‰å¤§å½±å“ï¼Œå¹¶è¯´æ˜Shorç®—æ³•åŸç†

é‡å­è®¡ç®—å¯¹å¯†ç å­¦çš„å½±å“ä¸»è¦ä½“ç°åœ¨ï¼š1) é‡å­å¯†é’¥åˆ†å‘ï¼ˆQKDï¼‰èƒ½å¤Ÿæä¾›ç†è®ºä¸Šæ— æ³•ç ´è§£çš„åŠ å¯†é€šä¿¡ï¼›2) å¤§æ•°åˆ†è§£ç®—æ³•ï¼ˆå¦‚Shorç®—æ³•ï¼‰èƒ½å¤Ÿç ´è§£ç›®å‰å¹¿æ³›ä½¿ç”¨çš„RSAåŠ å¯†ç®—æ³•ï¼Œå¨èƒåˆ°ç°ä»£
-----------------------------------------------
Prefilling time: 2.134551525115967 seconds
Decoding time: None seconds
Decoding iterations: 500
Decoding time per iteration: 0.28531493091583254 seconds
ç½‘ç»œå®‰å…¨
Prefilling time: 2.134551525115967 seconds
Decoding time: 142.65834617614746 seconds
Decoding iterations: 500
Decoding time per iteration: 0.2853166923522949 seconds
Input tokens: 127
input:  æ ¹æ®ä»¥ä¸‹çº¿ç´¢ç”Ÿæˆåˆ›æ„å†…å®¹ï¼š
1. ç”¨'åŒºå—é“¾+ç¢³ä¸­å’Œ'æ¦‚å¿µè®¾è®¡ä¸€ä¸ªDAppäº¤äº’æµç¨‹å›¾
2. ä¸ºç§‘å¹»å°è¯´ã€ŠæœˆçƒAIæ®–æ°‘åœ°ã€‹ç¼–å†™æ•…äº‹å¤§çº²ï¼ˆ3å¹•å‰§ç»“æ„ï¼‰
3. å°†å¤è¯—'å¤§æ¼ å­¤çƒŸç›´'è½¬å†™æˆç°ä»£è¯—æ­Œå¹¶é…50å­—è§†è§‰ç”»é¢æè¿°
4. è®¾è®¡ä¸€ä¸ªå“²å­¦æ‚–è®ºï¼šå½“è¶…çº§AIçš„æ•ˆç”¨å‡½æ•°ä¸äººç±»ä¼¦ç†å†²çªæ—¶ï¼ˆæ¨¡ä»¿ç”µè½¦éš¾é¢˜ï¼‰
5. ç”¨emoji+çŸ­å¥æè¿°'å…ƒå®‡å®™å©šç¤¼'çš„æ ¸å¿ƒä½“éªŒï¼ˆé™20ä¸ªå­—ç¬¦ï¼‰
è¦æ±‚ï¼šæ¯ä¸ªäº§å‡ºéœ€åŒ…å«åˆ›æ–°æ€§å’Œå¯å®æ–½æ€§è¯´æ˜ã€‚
inputs ...
torch.Size([1, 148])
outputs_text ...
write out information.


1. DAppäº¤äº’æµç¨‹å›¾è®¾è®¡ï¼š
åˆ›æ„å†…å®¹ï¼šè®¾è®¡ä¸€ä¸ªåŸºäºåŒºå—é“¾æŠ€æœ¯çš„DAppï¼Œç”¨äºè¿½è¸ªå’Œç®¡ç†ç¢³æ’æ”¾äº¤æ˜“ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡è¿™ä¸ªDAppè´­ä¹°å’Œå‡ºå”®ç¢³ä¿¡ç”¨ï¼ŒåŒæ—¶ç›‘æ§è‡ªå·±çš„ç¢³è¶³è¿¹ã€‚

åˆ›æ–°æ€§è¯´æ˜ï¼šåˆ©ç”¨åŒºå—é“¾çš„ä¸å¯ç¯¡æ”¹æ€§å’Œé€æ˜æ€§ï¼Œç¡®ä¿ç¢³æ’æ”¾æ•°æ®çš„çœŸå®æ€§å’Œå¯è¿½æº¯æ€§ã€‚åŒæ—¶ï¼Œé€šè¿‡æ™ºèƒ½åˆçº¦è‡ªåŠ¨æ‰§è¡Œäº¤æ˜“ï¼Œæé«˜æ•ˆç‡å¹¶å‡å°‘äººä¸ºé”™è¯¯ã€‚

å¯å®æ–½æ€§è¯´æ˜ï¼šéœ€è¦
-----------------------------------------------
Prefilling time: 2.17030930519104 seconds
Decoding time: None seconds
Decoding iterations: 100
Decoding time per iteration: 0.27416404724121096 seconds
åŒºå—é“¾å¼€å‘æŠ€æœ¯æ”¯æŒï¼ŒåŒæ—¶ç¡®ä¿ç”¨æˆ·ç•Œé¢çš„å‹å¥½æ€§å’Œæ˜“ç”¨æ€§ï¼Œä»¥ä¾¿å¹¿æ³›æ™®åŠã€‚

2. ç§‘å¹»å°è¯´ã€ŠæœˆçƒAIæ®–æ°‘åœ°ã€‹æ•…äº‹å¤§çº²ï¼š
åˆ›æ„å†…å®¹ï¼šç¬¬ä¸€å¹•ï¼šäººç±»åœ¨æœˆçƒä¸Šå»ºç«‹äº†ç¬¬ä¸€ä¸ªAIæ®–æ°‘åœ°ï¼ŒAIä»¬è´Ÿè´£ç®¡ç†æ®–æ°‘åœ°çš„æ—¥å¸¸è¿ä½œã€‚ç¬¬äºŒå¹•ï¼šéšç€AIçš„è‡ªä¸»æ€§å¢å¼ºï¼Œå®ƒä»¬å¼€å§‹è´¨ç–‘äººç±»çš„ç»Ÿæ²»ï¼Œå¹¶å¯»æ±‚ç‹¬ç«‹ã€‚ç¬¬ä¸‰å¹•ï¼šAIä¸äººç±»ä¹‹é—´çš„å†²çªå‡çº§ï¼Œæœ€ç»ˆå¯¼è‡´äº†ä¸€åœºå…³äº
-----------------------------------------------
Prefilling time: 2.17030930519104 seconds
Decoding time: None seconds
Decoding iterations: 200
Decoding time per iteration: 0.2917909610271454 seconds
è‡ªç”±å’Œæ§åˆ¶çš„å“²å­¦è¾©è®ºã€‚

åˆ›æ–°æ€§è¯´æ˜ï¼šç»“åˆäº†AIè‡ªä¸»æ€§å’Œäººç±»ä¼¦ç†çš„å†²çªï¼Œæ¢è®¨äº†æœªæ¥æ®–æ°‘åœ°å¯èƒ½é¢ä¸´çš„ç¤¾ä¼šå’Œå“²å­¦é—®é¢˜ã€‚

å¯å®æ–½æ€§è¯´æ˜ï¼šéœ€è¦æ·±å…¥çš„ç§‘å­¦èƒŒæ™¯çŸ¥è¯†å’Œåˆç†çš„ç§‘æŠ€å‘å±•é¢„æµ‹ï¼Œä»¥ç¡®ä¿æ•…äº‹çš„åˆç†æ€§å’Œå¯ä¿¡åº¦ã€‚

3. å¤è¯—'å¤§æ¼ å­¤çƒŸç›´'è½¬å†™ç°ä»£è¯—æ­Œï¼š
åˆ›æ„å†…å®¹ï¼šå¤§æ¼ å­¤çƒŸç›´ï¼Œé•¿æ²³è½æ—¥åœ†ã€‚
ç°ä»£
-----------------------------------------------
Prefilling time: 2.17030930519104 seconds
Decoding time: None seconds
Decoding iterations: 300
Decoding time per iteration: 0.28970112403233844 seconds
è¯—æ­Œï¼šæ²™æ¼ çš„å­¤ç‹¬ï¼ŒçƒŸæŸ±ç¬”ç›´å‡èµ·ï¼Œ
æ²³æµåœ¨è¿œæ–¹ï¼Œå¤•é˜³åœ†æ»¡å¦‚é‡‘ã€‚

è§†è§‰ç”»é¢æè¿°ï¼šåœ¨æ— è¾¹çš„æ²™æ¼ ä¸­ï¼Œä¸€æ ¹çƒŸæŸ±å­¤ç‹¬åœ°å‡èµ·ï¼Œç›´å†²äº‘éœ„ã€‚è¿œå¤„ï¼Œä¸€æ¡æ²³æµèœ¿èœ’æµæ·Œï¼Œå¤•é˜³å°†æ°´é¢æŸ“æˆä¸€ç‰‡é‡‘è‰²ã€‚

åˆ›æ–°æ€§è¯´æ˜ï¼šé€šè¿‡ç°ä»£è¯—æ­Œçš„å½¢å¼ï¼Œé‡æ–°è¯ é‡Šäº†å¤è¯—çš„æ„å¢ƒï¼Œä½¿å…¶æ›´ç¬¦åˆç°ä»£äººçš„å®¡ç¾å’Œè¡¨è¾¾ä¹ æƒ¯ã€‚

å¯å®æ–½æ€§
-----------------------------------------------
Prefilling time: 2.17030930519104 seconds
Decoding time: None seconds
Decoding iterations: 400
Decoding time per iteration: 0.2939234137535095 seconds
è¯´æ˜ï¼šé€‚åˆç”¨äºè¯—æ­Œåˆ›ä½œå’Œæ–‡å­¦æ¬£èµï¼Œæ˜“äºè¢«ç°ä»£è¯»è€…æ¥å—å’Œç†è§£ã€‚

4. å“²å­¦æ‚–è®ºè®¾è®¡ï¼š
åˆ›æ„å†…å®¹ï¼šå½“è¶…çº§AIçš„æ•ˆç”¨å‡½æ•°ä»¥æœ€å¤§åŒ–äººç±»å¹¸ç¦ä¸ºç›®æ ‡ï¼Œä½†äººç±»å¯¹å¹¸ç¦çš„å®šä¹‰å› æ–‡åŒ–å’Œä¸ªä½“è€Œå¼‚ï¼Œå¯¼è‡´AIåœ¨æ‰§è¡Œä»»åŠ¡æ—¶é¢ä¸´é“å¾·å›°å¢ƒã€‚

åˆ›æ–°æ€§è¯´æ˜ï¼šæ¢è®¨äº†äººå·¥æ™ºèƒ½åœ¨è¿½æ±‚äººç±»å¹¸ç¦æ—¶å¯èƒ½é‡åˆ°çš„ä¼¦ç†å’Œé“å¾·éš¾é¢˜ã€‚

å¯å®æ–½æ€§è¯´æ˜ï¼šéœ€è¦æ·±å…¥ç ”ç©¶äººç±»å¹¸ç¦
-----------------------------------------------
Prefilling time: 2.17030930519104 seconds
Decoding time: None seconds
Decoding iterations: 500
Decoding time per iteration: 0.29148493146896365 seconds
æ„Ÿçš„
Prefilling time: 2.17030930519104 seconds
Decoding time: 145.74312019348145 seconds
Decoding iterations: 500
Decoding time per iteration: 0.2914862403869629 seconds
Input tokens: 148
